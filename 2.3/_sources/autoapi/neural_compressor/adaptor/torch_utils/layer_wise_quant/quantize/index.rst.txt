:py:mod:`neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize`
=========================================================================

.. py:module:: neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize

.. autoapi-nested-parse::

   Layer wise quantization.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize.LayerWiseQuant




.. py:class:: LayerWiseQuant(q_model, pretrained_model_name_or_path, op_cfgs, calib_data, smooth_quant=False, output_dir=None, device='cpu', alpha=0.5)


   Layer wise quantization.

   Layer-by-layer quantize the model, in order to save memomery.



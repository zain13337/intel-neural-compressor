<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>neural_compressor.torch.amp.autocast &mdash; Intel® Neural Compressor 2.6 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/graphviz.css" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/custom.css" />

  
<script type="text/javascript">
  // Configure TMS settings
  window.wapProfile = 'profile-microsite'; // This is mapped by WAP authorize value
  window.wapLocalCode = 'us-en'; // Dynamically set per localized site, see mapping table for values
  window.wapSection = "neural-compressor"; // WAP team will give you a unique section for your site
  window.wapEnv = 'prod'; // environment to be use in Adobe Tags.
  // Load TMS
  (() => {
        let url = 'https://www.intel.com/content/dam/www/global/wap/main/wap-microsite.js';
        let po = document.createElement('script'); po.type = 'text/javascript'; po.async = true; po.src = url;
        let s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  }) ();
</script>

    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../index.html" class="icon icon-home">
            Intel® Neural Compressor
          </a>
            <div class="version">
              <a href="../../../../../../versions.html">latest▼</a>
              <p>Click link above to switch version</p>
            </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../docs/source/get_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../docs/source/installation_guide.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../docs/source/user_guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../docs/source/examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../docs/source/api-doc/apis.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../docs/source/releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../docs/source/legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../docs/source/SECURITY.html">Security Policy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">Repo</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">Intel® Neural Compressor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active"><code class="xref py py-mod docutils literal notranslate"><span class="pre">neural_compressor.torch.amp.autocast</span></code></li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../_sources/autoapi/neural_compressor/torch/amp/autocast/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-neural_compressor.torch.amp.autocast">
<span id="neural-compressor-torch-amp-autocast"></span><h1><a class="reference internal" href="#module-neural_compressor.torch.amp.autocast" title="neural_compressor.torch.amp.autocast"><code class="xref py py-mod docutils literal notranslate"><span class="pre">neural_compressor.torch.amp.autocast</span></code></a><a class="headerlink" href="#module-neural_compressor.torch.amp.autocast" title="Permalink to this heading"></a></h1>
<section id="module-contents">
<h2>Module Contents<a class="headerlink" href="#module-contents" title="Permalink to this heading"></a></h2>
<section id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this heading"></a></h3>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#neural_compressor.torch.amp.autocast.autocast" title="neural_compressor.torch.amp.autocast.autocast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">autocast</span></code></a></p></td>
<td><p>Instances of <a class="reference internal" href="#neural_compressor.torch.amp.autocast.autocast" title="neural_compressor.torch.amp.autocast.autocast"><code class="xref py py-class docutils literal notranslate"><span class="pre">autocast</span></code></a> serve as context managers or decorators that</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt class="sig sig-object py" id="neural_compressor.torch.amp.autocast.autocast">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_compressor.torch.amp.autocast.</span></span><span class="sig-name descname"><span class="pre">autocast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.types._dtype</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enabled</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_enabled</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/intel/neural-compressor/blob/master/neural_compressor/torch/amp/autocast.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_compressor.torch.amp.autocast.autocast" title="Permalink to this definition"></a></dt>
<dd><p>Instances of <a class="reference internal" href="#neural_compressor.torch.amp.autocast.autocast" title="neural_compressor.torch.amp.autocast.autocast"><code class="xref py py-class docutils literal notranslate"><span class="pre">autocast</span></code></a> serve as context managers or decorators that
allow regions of your script to run in mixed precision.</p>
<p>In these regions, ops run in an op-specific dtype chosen by autocast
to improve performance while maintaining accuracy.</p>
<p>When entering an autocast-enabled region, Tensors may be any type.
You should not call <code class="docutils literal notranslate"><span class="pre">half()</span></code> or <code class="docutils literal notranslate"><span class="pre">bfloat16()</span></code> on your model(s) or inputs when using autocasting.</p>
<p><a class="reference internal" href="#neural_compressor.torch.amp.autocast.autocast" title="neural_compressor.torch.amp.autocast.autocast"><code class="xref py py-class docutils literal notranslate"><span class="pre">autocast</span></code></a> should wrap only the forward pass(es) of your network, including the loss
computation(s).  Backward passes under autocast are not recommended.
Backward ops run in the same type that autocast used for corresponding forward ops.</p>
<blockquote>
<div><p># Enables autocasting for the inference pass
with torch.autocast(device_type=”hpu”, dtype=torch.float8_e4m3fn):</p>
<blockquote>
<div><p>output = model(input)</p>
</div></blockquote>
</div></blockquote>
<p><a class="reference internal" href="#neural_compressor.torch.amp.autocast.autocast" title="neural_compressor.torch.amp.autocast.autocast"><code class="xref py py-class docutils literal notranslate"><span class="pre">autocast</span></code></a> can also be used as a decorator, e.g., on the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of your model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">AutocastModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="o">...</span>
    <span class="nd">@torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>The autocast state is thread-local.  If you want it enabled in a new thread, the context manager or decorator
must be invoked in that thread.  This affects <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.DataParallel</span></code> and
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.parallel.DistributedDataParallel</span></code> when used with more than one GPU per process
(see <span class="xref std std-ref">Working with Multiple GPUs</span>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device_type</strong> (<em>str</em><em>, </em><em>required</em>) – Device type to use. Possible values are: ‘cuda’, ‘cpu’, ‘xpu’ and ‘hpu’.
The type is the same as the <cite>type</cite> attribute of a <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code>.
Thus, you may obtain the device type of a tensor using <cite>Tensor.device.type</cite>.</p></li>
<li><p><strong>enabled</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether autocasting should be enabled in the region.
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>dtype</strong> (<em>torch_dtype</em><em>, </em><em>optional</em>) – Whether to use torch.float16 or torch.bfloat16.</p></li>
<li><p><strong>cache_enabled</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether the weight cache inside autocast should be enabled.
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Intel® Neural Compressor, Intel.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   <jinja2.runtime.BlockReference object at 0x7fc37f8e9450> 
  <p></p><div><a href='https://www.intel.com/content/www/us/en/privacy/intel-cookie-notice.html' data-cookie-notice='true'>Cookies</a> <a href='https://www.intel.com/content/www/us/en/privacy/intel-privacy-notice.html'>| Privacy</a></div>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
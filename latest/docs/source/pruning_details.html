<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Pruning details &mdash; Intel® Neural Compressor 2.0 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Intel® Neural Compressor
          </a>
            <div class="version">
              <a href="../../../versions.html">latest▼</a>
              <p>Click link above to switch version</p>
            </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="get_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation_guide.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="user_guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="api-doc/apis.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="SECURITY.html">Security Policy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">Repo</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Intel® Neural Compressor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Pruning details</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/docs/source/pruning_details.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="pruning-details">
<h1>Pruning details<a class="headerlink" href="#pruning-details" title="Permalink to this heading"></a></h1>
<ol class="simple">
<li><p><a class="reference external" href="#introduction">Introduction</a></p></li>
</ol>
<blockquote>
<div><blockquote>
<div><blockquote>
<div><p><a class="reference external" href="#neural-network-pruning">Neural Network Pruning</a></p>
</div></blockquote>
</div></blockquote>
</div></blockquote>
<blockquote>
<div><blockquote>
<div><blockquote>
<div><p><a class="reference external" href="#pruning-patterns">Pruning Patterns</a></p>
</div></blockquote>
</div></blockquote>
</div></blockquote>
<blockquote>
<div><blockquote>
<div><blockquote>
<div><p><a class="reference external" href="#pruning-criteria">Pruning Criteria</a></p>
</div></blockquote>
</div></blockquote>
</div></blockquote>
<blockquote>
<div><blockquote>
<div><blockquote>
<div><p><a class="reference external" href="#pruning-schedule">Pruning Schedule</a></p>
</div></blockquote>
</div></blockquote>
</div></blockquote>
<blockquote>
<div><blockquote>
<div><blockquote>
<div><p><a class="reference external" href="#pruning-type">Pruning Type</a></p>
</div></blockquote>
</div></blockquote>
</div></blockquote>
<blockquote>
<div><blockquote>
<div><blockquote>
<div><p><a class="reference external" href="#regularization">Regularization</a></p>
</div></blockquote>
</div></blockquote>
</div></blockquote>
<ol class="simple">
<li><p><a class="reference external" href="#examples">Pruning examples</a></p></li>
<li><p><a class="reference external" href="#reference">Reference</a></p></li>
</ol>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading"></a></h2>
<section id="neural-network-pruning">
<h3>Neural Network Pruning<a class="headerlink" href="#neural-network-pruning" title="Permalink to this heading"></a></h3>
<p>Neural network pruning is a promising model compression technique that removes the least important parameters in the network and achieves compact architectures with minimal accuracy drop and maximal inference acceleration. As state-of-the-art model sizes have grown at an unprecedented speed, pruning has become increasingly crucial for reducing the computational and memory footprint that huge neural networks require.</p>
</section>
<section id="pruning-patterns">
<h3>Pruning Patterns<a class="headerlink" href="#pruning-patterns" title="Permalink to this heading"></a></h3>
<ul>
<li><p>Unstructured Pruning</p>
<p>Unstructured pruning means pruning the least salient connections in the model. The nonzero patterns are irregular and could be anywhere in the matrix.</p>
</li>
<li><p>Structured Pruning</p>
<p>Structured pruning means pruning parameters in groups and deleting entire blocks, filters, or channels according to some pruning criterions. In general, structured pruning leads to lower accuracy due to restrictive structure compared to unstructured pruning but it can significantly accelerate the model execution as it fits better with hardware designs.</p>
</li>
</ul>
</section>
<section id="pruning-criteria">
<h3>Pruning Criteria<a class="headerlink" href="#pruning-criteria" title="Permalink to this heading"></a></h3>
<p>Pruning criteria determines how should the weights of a neural network be scored and pruned. The magnitude and gradient are widely used to score the weights.</p>
<ul>
<li><p>Magnitude</p>
<p>The algorithm prunes the weight by the lowest absolute value at each layer with given sparsity target.</p>
</li>
<li><p>Gradient</p>
<p>The algorithm prunes the weight by the lowest gradient value at each layer with given sparsity target.</p>
</li>
<li><p>SNIP</p>
<p>The algorithm prunes the dense model at its initialization, by analyzing the weights’ effect to the loss function when they are masked. Please refer to the original <a class="reference external" href="https://arxiv.org/abs/1810.02340">paper</a> for details</p>
</li>
<li><p>SNIP with momentum</p>
<p>The algorithm improves original SNIP algorithms and introduces weights’ score maps which updates in a momentum way.\</p>
<p>In the following formula, $n$ is the pruning step and $W$ and $G$ are model’s weights and gradients respectively.</p>
<p>$$Score_{n} = 1.0 \times Score_{n-1} + 0.9 \times |W_{n} \times G_{n}|$$</p>
</li>
</ul>
</section>
<section id="pruning-schedule">
<h3>Pruning Schedule<a class="headerlink" href="#pruning-schedule" title="Permalink to this heading"></a></h3>
<p>Pruning schedule defines the way the model reach the target sparsity (the ratio of pruned weights).</p>
<ul>
<li><p>One-shot Pruning</p>
<p>One-shot pruning means the model is pruned to its target sparsity with one single step. This pruning method often works at model’s initialization step. It can easily cause accuracy drop, but save much training time.</p>
</li>
<li><p>Iterative Pruning</p>
<p>Iterative pruning means the model is gradually pruned to its target sparsity during a training process. The pruning process contains several pruning steps, and each step raises model’s sparsity to a higher value. In the final pruning step, the model reaches target sparsity and the pruning process ends.</p>
</li>
</ul>
</section>
<section id="pruning-type">
<h3>Pruning Type<a class="headerlink" href="#pruning-type" title="Permalink to this heading"></a></h3>
<ul>
<li><p>Pattern_lock Pruning</p>
<p>Pattern_lock pruning type uses masks of a fixed pattern during the pruning process. It locks the sparsity pattern in finetuning phase by freezing those zero values of weight tensor during weight update of training. It can be applied in the following scenario: after the model is pruned under a large dataset, pattern lock can be used to retrain the sparse model on a downstream task (a smaller dataset). Please refer to <a class="reference external" href="https://arxiv.org/pdf/2111.05754.pdf">Prune once for all</a> for more information.</p>
</li>
<li><p>Progressive Pruning</p>
<p>Progressive pruning aims at smoothing the structured pruning by automatically interpolating a group of interval masks during the pruning process. In this method, a sequence of masks are generated to enable a more flexible pruning process and those masks would gradually change into ones to fit the target pruning structure.
Progressive pruning is used mainly for channel-wise pruning and currently only supports NxM pruning pattern.</p>
<div style = "width: 77%; margin-bottom: 2%;">
  <a target="_blank" href="./imgs/pruning/progressive_pruning.png">
    <img src="./imgs/pruning/progressive_pruning.png" alt="Architecture" width=800 height=500>
  </a>
</div>
(a) refers to the traditional structured iterative pruning; (b, c, d) demonstrates some typical implementations of mask interpolation. (b) uses masks with smaller structured blocks during every pruning step. (c) inserts masks with smaller structured blocks between every pruning steps. (d) inserts unstructured masks which prune some weights by referring to pre-defined score maps. We use (d) as the mask interpolation implementation of progressive pruning.</li>
</ul>
</section>
<section id="pruning-scope">
<h3>Pruning Scope<a class="headerlink" href="#pruning-scope" title="Permalink to this heading"></a></h3>
<p>Range of sparse score calculation in iterative pruning, default scope is global.</p>
<ul>
<li><p>Global</p>
<p>The score map is computed out of entire parameters, Some layers are higher than the target sparsity and some are lower, the total sparsity of the model reaches the target.</p>
</li>
<li><p>Local</p>
<p>The score map is computed from the corresponding layer’s weight, The sparsity of each layer is equal to the target.</p>
</li>
</ul>
</section>
<section id="sparsity-decay-type">
<h3>Sparsity Decay Type<a class="headerlink" href="#sparsity-decay-type" title="Permalink to this heading"></a></h3>
<p>Growth rules for the sparsity of iterative pruning, “exp”, “linear”, “cos” and “cube” are available，We use exp by default.</p>
</section>
<section id="regularization">
<h3>Regularization<a class="headerlink" href="#regularization" title="Permalink to this heading"></a></h3>
<p>Regularization is a technique that discourages learning a more complex model and therefore performs variable-selection.</p>
<ul>
<li><p>Group Lasso</p>
<p>The main idea of Group Lasso is to construct an objective function that penalizes the L2 parametrization of the grouped variables, determines the coefficients of some groups of variables to be zero, and obtains a refined model by feature filtering.</p>
</li>
</ul>
</section>
</section>
<section id="pruning-examples">
<h2>Pruning Examples<a class="headerlink" href="#pruning-examples" title="Permalink to this heading"></a></h2>
<p>We validate the pruning technique on typical models across various domains (including CV and NLP).</p>
</section>
<section id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Permalink to this heading"></a></h2>
<p>[1] Namhoon Lee, Thalaiyasingam Ajanthan, and Philip Torr. SNIP: Single-shot network pruning based on connection sensitivity. In International Conference on Learning Representations, 2019.</p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Intel® Neural Compressor, Intel.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
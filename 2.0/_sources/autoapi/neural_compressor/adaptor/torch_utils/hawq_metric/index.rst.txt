:py:mod:`neural_compressor.adaptor.torch_utils.hawq_metric`
===========================================================

.. py:module:: neural_compressor.adaptor.torch_utils.hawq_metric

.. autoapi-nested-parse::

   Torch Utils for Hessian Aware Weighted Quantization.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   neural_compressor.adaptor.torch_utils.hawq_metric.Node_collector
   neural_compressor.adaptor.torch_utils.hawq_metric.HessianTrace



Functions
~~~~~~~~~

.. autoapisummary::

   neural_compressor.adaptor.torch_utils.hawq_metric.compare_weights
   neural_compressor.adaptor.torch_utils.hawq_metric.hawq_top



.. py:class:: Node_collector(m)

   Define Collector based on hook, which is used to record the intermediate result.

   .. py:method:: hook_fn_act(m, inp, outp)

      Get out and in features.


   .. py:method:: remove()

      Remove handle.



.. py:class:: HessianTrace(model, dataloader, q_model, criterion=None)

   HessianTrace Class.

   Please refer to Yao, Zhewei, et al. "Pyhessian: Neural networks through the lens of the hessian."
   2020 IEEE international conference on big data (Big data). IEEE, 2020.
   Dong, Zhen, et al. "Hawq-v2: Hessian aware trace-weighted quantization of neural networks."
   Advances in neural information processing systems 33 (2020): 18518-18529.
   https://github.com/openvinotoolkit/nncf/blob/develop/nncf/torch/quantization/hessian_trace.py

   .. py:method:: is_fused_module(module)

      This is a helper function for `_propagate_qconfig_helper` to detecte if this module is fused.

      :param module: the input module.
      :type module: object

      :returns: is fused or not
      :rtype: (bool)


   .. py:method:: mse_metric_gap(fp32_tensor, dequantize_tensor)

      Calculate the euclidean distance between fp32 tensor and int8 dequantize tensor.

      :param fp32_tensor: The FP32 tensor.
      :type fp32_tensor: tensor
      :param dequantize_tensor: The INT8 dequantize tensor.
      :type dequantize_tensor: tensor


   .. py:method:: get_fused_mapping()

      Map the ops of both fused or not modules to weights.

      :returns: weights of each op.
                op_list (list): ops.
      :rtype: weight_to_op (dict)


   .. py:method:: get_device(model: torch.nn.Module)

      Get the device.

      :param model: the input model.
      :type model: torch.nn.Module


   .. py:method:: register_act_grad_hooks(model)

      Append hook handles.


   .. py:method:: reset_act_gradient_and_hooks()

      Reset hook.


   .. py:method:: get_params()

      Get weight names and parameters.


   .. py:method:: get_vtHv_weight(params, num_samples)

      Get vtHv weight.


   .. py:method:: get_weight_traces(num_samples)

      Get op names to trace.

      :param num_samples: sample number.
      :type num_samples: int

      :returns: op names to trace.
      :rtype: op_name_to_trace (dict)


   .. py:method:: get_act_traces(num_samples)

      Get op names to trace.

      :param num_samples: sample number.
      :type num_samples: int

      :returns: res_dict (dict).


   .. py:method:: get_act_gap(fp32_model, q_model)

      Estimates each activation gap between quantized model and float model.


   .. py:method:: get_avg_traces(enable_act=True, num_samples=32)

      Estimates average hessian trace for each parameter.



.. py:function:: compare_weights(float_dict: Dict[str, Any], quantized_dict: Dict[str, Any]) -> Dict[str, Dict[str, torch.Tensor]]

   Compare the weights of the float module with its corresponding quantized module.

   Returns a dict with key corresponding to module names and each entry being
   a dictionary with two keys 'float' and 'quantized', containing the float and
   quantized weights. This dict can be used to compare and compute the quantization
   error of the weights of float and quantized models.

   Example usage::

       wt_compare_dict = compare_weights(
           float_model.state_dict(), qmodel.state_dict())
       for key in wt_compare_dict:
           print(
               key,
               compute_error(
                   wt_compare_dict[key]['float'],
                   wt_compare_dict[key]['quantized'].dequantize()
               )
           )

   :param float_dict: state dict of the float model.
   :param quantized_dict: state dict of the quantized model.

   :returns: dict with key corresponding to module names and each entry being
             a dictionary with two keys 'float' and 'quantized', containing the float and
             quantized weights.
   :rtype: weight_dict


.. py:function:: hawq_top(fp32_model, q_model, dataloader, criterion, enable_act)

   Enable hawq on an HessianTrace object and returns op list.



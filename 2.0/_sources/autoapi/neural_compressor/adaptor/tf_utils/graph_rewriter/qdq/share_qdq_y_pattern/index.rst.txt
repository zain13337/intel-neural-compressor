:py:mod:`neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern`
===================================================================================

.. py:module:: neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern

.. autoapi-nested-parse::

   Share QDQ for ITEX Y pattern Graph Rewriter.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern.ShareQDQForItexYPatternOptimizer




.. py:class:: ShareQDQForItexYPatternOptimizer(model)

   Bases: :py:obj:`neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base.GraphRewriterBase`

   Insert Q/DQ op before one input of Add to enable Conv/MatMul + BiasAdd + Add + Relu fusion for ITEX.

   Only 1 Q/DQ before Add op need to be inserted. Insert 2 Q/DQ breaks the ITEX fusion pattern.

   .. py:method:: do_transformation()

      Share the QDQ of one output of Relu node with the another output which is Add node.




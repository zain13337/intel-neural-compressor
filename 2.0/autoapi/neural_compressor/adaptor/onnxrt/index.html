

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>neural_compressor.adaptor.onnxrt &mdash; Intel® Neural Compressor  documentation</title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/sphinx_highlight.js"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> Intel® Neural Compressor
          

          
          </a>

          
            
            
            <div class="version">
              <a href="../../../../../versions.html">2.0▼</a>
              <p>Click link above to switch version</p>
            </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../Welcome.html">Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api-documentation/apis.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">Intel® Neural Compressor repository</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">Intel® Neural Compressor</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li><code class="xref py py-mod docutils literal notranslate"><span class="pre">neural_compressor.adaptor.onnxrt</span></code></li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../../_sources/autoapi/neural_compressor/adaptor/onnxrt/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="module-neural_compressor.adaptor.onnxrt">
<span id="neural-compressor-adaptor-onnxrt"></span><h1><a class="reference internal" href="#module-neural_compressor.adaptor.onnxrt" title="neural_compressor.adaptor.onnxrt"><code class="xref py py-mod docutils literal notranslate"><span class="pre">neural_compressor.adaptor.onnxrt</span></code></a><a class="headerlink" href="#module-neural_compressor.adaptor.onnxrt" title="Permalink to this heading">¶</a></h1>
<section id="module-contents">
<h2>Module Contents<a class="headerlink" href="#module-contents" title="Permalink to this heading">¶</a></h2>
<section id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this heading">¶</a></h3>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor" title="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ONNXRUNTIMEAdaptor</span></code></a></p></td>
<td><p>The ONNXRT adaptor layer, do onnx-rt quantization, calibration, inspect layer tensors.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRT_QLinearOpsAdaptor" title="neural_compressor.adaptor.onnxrt.ONNXRT_QLinearOpsAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ONNXRT_QLinearOpsAdaptor</span></code></a></p></td>
<td><p>The ONNXRT adaptor layer, do onnx-rt quantization, calibration, inspect layer tensors.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRT_IntegerOpsAdaptor" title="neural_compressor.adaptor.onnxrt.ONNXRT_IntegerOpsAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ONNXRT_IntegerOpsAdaptor</span></code></a></p></td>
<td><p>The ONNXRT adaptor layer, do onnx-rt quantization, calibration, inspect layer tensors.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRT_QDQAdaptor" title="neural_compressor.adaptor.onnxrt.ONNXRT_QDQAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ONNXRT_QDQAdaptor</span></code></a></p></td>
<td><p>The ONNXRT adaptor layer, do onnx-rt quantization, calibration, inspect layer tensors.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery" title="neural_compressor.adaptor.onnxrt.ONNXRTQuery"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ONNXRTQuery</span></code></a></p></td>
<td><p>Base class that defines Query Interface.</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_compressor.adaptor.onnxrt.</span></span><span class="sig-name descname"><span class="pre">ONNXRUNTIMEAdaptor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">framework_specific_info</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="../adaptor/index.html#neural_compressor.adaptor.adaptor.Adaptor" title="neural_compressor.adaptor.adaptor.Adaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">neural_compressor.adaptor.adaptor.Adaptor</span></code></a></p>
<p>The ONNXRT adaptor layer, do onnx-rt quantization, calibration, inspect layer tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>framework_specific_info</strong> (<em>dict</em>) – framework specific configuration for quantization.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.quantize">
<span class="sig-name descname"><span class="pre">quantize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tune_cfg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.quantize" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>The function is used to do calibration and quanitization in post-training</dt><dd><p>quantization.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tune_cfg</strong> (<em>dict</em>) – quantization config.</p></li>
<li><p><strong>model</strong> (<em>object</em>) – model need to do quantization.</p></li>
<li><p><strong>data_loader</strong> (<em>object</em>) – calibration dataset.</p></li>
<li><p><strong>q_func</strong> (<em>optional</em>) – training function for quantization aware training mode,
unimplement yet for onnx.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>quantized model</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.recover">
<span class="sig-name descname"><span class="pre">recover</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q_config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.recover" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute the recover process on the specified model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – model need to do quantization.</p></li>
<li><p><strong>q_config</strong> (<em>dict</em>) – recover configuration</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>quantized model</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.inspect_tensor">
<span class="sig-name descname"><span class="pre">inspect_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">op_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inspect_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'activation'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_to_disk</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantization_cfg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.inspect_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>The function is used by tune strategy class for dumping tensor info.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.set_tensor">
<span class="sig-name descname"><span class="pre">set_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.set_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>The function is used by tune strategy class for setting tensor back to model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – The model to set tensor. Usually it is quantized model.</p></li>
<li><p><strong>tensor_dict</strong> (<em>dict</em>) – <p>The tensor dict to set. Note the numpy array contains float
value, adaptor layer has the responsibility to quantize to
int8 or int32 to set into the quantized model if needed.
The dict format is something like:
{</p>
<blockquote>
<div><p>’weight0_name’: numpy.array,
‘bias0_name’: numpy.array,
…</p>
</div></blockquote>
<p>}</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.query_fw_capability">
<span class="sig-name descname"><span class="pre">query_fw_capability</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.query_fw_capability" title="Permalink to this definition">¶</a></dt>
<dd><p>The function is used to query framework capability.
TODO: will be replaced by framework query API</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> – onnx model</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>quantization capability</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">postprocess</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measurer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensorboard</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fp32_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>The function is for evaluation if no given eval func</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_graph</strong> – onnx model for evaluation</p></li>
<li><p><strong>dataloader</strong> – dataloader for evaluation. neural_compressor.data.dataloader.ONNXDataLoader</p></li>
<li><p><strong>postprocess</strong> – post-process for evalution. neural_compressor.data.transform.ONNXTransforms</p></li>
<li><p><strong>metrics</strong> – : metrics for evaluation. neural_compressor.metric.ONNXMetrics</p></li>
<li><p><strong>measurer</strong> – neural_compressor.objective.Measurer</p></li>
<li><p><strong>iteration</strong> (<em>int</em>) – max iterations of evaluaton.</p></li>
<li><p><strong>tensorboard</strong> (<em>bool</em>) – whether to use tensorboard for visualizaton</p></li>
<li><p><strong>fp32_baseline</strong> (<em>boolen</em><em>, </em><em>optional</em>) – only for compare_label=False pipeline</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(float) evaluation results. acc, f1 e.g.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.save" title="Permalink to this definition">¶</a></dt>
<dd><p>save model</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>ModelProto</em>) – model to save</p></li>
<li><p><strong>path</strong> (<em>str</em>) – save path</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRT_QLinearOpsAdaptor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_compressor.adaptor.onnxrt.</span></span><span class="sig-name descname"><span class="pre">ONNXRT_QLinearOpsAdaptor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">framework_specific_info</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRT_QLinearOpsAdaptor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor" title="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ONNXRUNTIMEAdaptor</span></code></a></p>
<p>The ONNXRT adaptor layer, do onnx-rt quantization, calibration, inspect layer tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>framework_specific_info</strong> (<em>dict</em>) – framework specific configuration for quantization.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRT_IntegerOpsAdaptor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_compressor.adaptor.onnxrt.</span></span><span class="sig-name descname"><span class="pre">ONNXRT_IntegerOpsAdaptor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">framework_specific_info</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRT_IntegerOpsAdaptor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor" title="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ONNXRUNTIMEAdaptor</span></code></a></p>
<p>The ONNXRT adaptor layer, do onnx-rt quantization, calibration, inspect layer tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>framework_specific_info</strong> (<em>dict</em>) – framework specific configuration for quantization.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRT_QDQAdaptor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_compressor.adaptor.onnxrt.</span></span><span class="sig-name descname"><span class="pre">ONNXRT_QDQAdaptor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">framework_specific_info</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRT_QDQAdaptor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor" title="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ONNXRUNTIMEAdaptor</span></code></a></p>
<p>The ONNXRT adaptor layer, do onnx-rt quantization, calibration, inspect layer tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>framework_specific_info</strong> (<em>dict</em>) – framework specific configuration for quantization.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRTQuery">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_compressor.adaptor.onnxrt.</span></span><span class="sig-name descname"><span class="pre">ONNXRTQuery</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">local_config_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="../query/index.html#neural_compressor.adaptor.query.QueryBackendCapability" title="neural_compressor.adaptor.query.QueryBackendCapability"><code class="xref py py-obj docutils literal notranslate"><span class="pre">neural_compressor.adaptor.query.QueryBackendCapability</span></code></a></p>
<p>Base class that defines Query Interface.
Each adaption layer should implement the inherited class for specific backend on their own.</p>
<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_version">
<span class="sig-name descname"><span class="pre">get_version</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_version" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the current backend version infomation.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>version string.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>[string]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_precisions">
<span class="sig-name descname"><span class="pre">get_precisions</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_precisions" title="Permalink to this definition">¶</a></dt>
<dd><p>Get supported precisions for current backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the precisions’ name.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>[string list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_op_types">
<span class="sig-name descname"><span class="pre">get_op_types</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_op_types" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the supported op types by all precisions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A list composed of dictionary which key is precision
and value is the op types.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>[dictionary list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_quantization_capability">
<span class="sig-name descname"><span class="pre">get_quantization_capability</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_quantization_capability" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the supported op types’ quantization capability.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A list composed of dictionary which key is precision
and value is a dict that describes all op types’ quantization capability.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>[dictionary list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_op_types_by_precision">
<span class="sig-name descname"><span class="pre">get_op_types_by_precision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">precision</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_op_types_by_precision" title="Permalink to this definition">¶</a></dt>
<dd><p>Get op types per precision</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>precision</strong> (<em>string</em>) – precision name</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list composed of op type.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>[string list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_graph_optimization">
<span class="sig-name descname"><span class="pre">get_graph_optimization</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_graph_optimization" title="Permalink to this definition">¶</a></dt>
<dd><p>Get onnxruntime graph optimization level</p>
</dd></dl>

</dd></dl>

</section>
</section>
</section>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, Intel® Neural Compressor.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>
<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>DataLoader &mdash; Intel® Neural Compressor 2.1 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Intel® Neural Compressor
          </a>
            <div class="version">
              <a href="../../../versions.html">2.1▼</a>
              <p>Click link above to switch version</p>
            </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="get_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation_guide.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="user_guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="api-doc/apis.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="SECURITY.html">Security Policy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">Repo</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Intel® Neural Compressor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">DataLoader</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/docs/source/dataloader.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="dataloader">
<h1>DataLoader<a class="headerlink" href="#dataloader" title="Permalink to this heading"></a></h1>
<ol class="simple">
<li><p><a class="reference external" href="#introduction">Introduction</a></p></li>
<li><p><a class="reference external" href="#supported-framework-dataloader-matrix">Supported Framework Dataloader Matrix</a></p></li>
<li><p><a class="reference external" href="#get-start-with-dataloader-api">Get Start with Dataloader API</a></p></li>
<li><p><a class="reference external" href="#examples">Examples</a></p></li>
</ol>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading"></a></h2>
<p>Deep Learning often encounters large datasets that are memory-consuming. Previously, working with large datasets required loading them into memory all at once. The constant lack of memory resulted in the need for an efficient data generation scheme. This is not only about handling the lack of memory in large datasets, but also about making the process of loading data faster using a multi-processing thread. We call the data generation object a DataLoader.</p>
<p>With the importance of a dataloader, different frameworks can have their own DataLoader module. As for Intel® Neural Compressor, it has implemented an internal dataloader and provides a unified DataLoader API for the following three reasons:</p>
<ul class="simple">
<li><p>The framework-specific dataloader has different features and APIs that will make it hard to use them same way in Neural Compressor.</p></li>
<li><p>Neural Compressor treats batch size as a tuning parameter which means it can dynamically change the batch size to reach the accuracy goal.</p></li>
<li><p>Internal dataloader makes it easy to config dataloaders in a yaml file without any code modification.</p></li>
</ul>
<p>The internal dataloader takes a <a class="reference internal" href="dataset.html"><span class="doc">dataset</span></a> as the input parameter and loads data from the dataset when needed. In special cases, users can also define their own dataloader classes, which must have <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> attribute and <code class="docutils literal notranslate"><span class="pre">__iter__</span></code> function.</p>
</section>
<section id="supported-framework-dataloader-matrix">
<h2>Supported Framework Dataloader Matrix<a class="headerlink" href="#supported-framework-dataloader-matrix" title="Permalink to this heading"></a></h2>
<table border="1" class="docutils">
<thead>
<tr>
<th>Framework</th>
<th style="text-align: center;">Status</th>
</tr>
</thead>
<tbody>
<tr>
<td>TensorFlow</td>
<td style="text-align: center;">&#10004;</td>
</tr>
<tr>
<td>PyTorch</td>
<td style="text-align: center;">&#10004;</td>
</tr>
<tr>
<td>ONNX Runtime</td>
<td style="text-align: center;">&#10004;</td>
</tr>
<tr>
<td>MXNet</td>
<td style="text-align: center;">&#10004;</td>
</tr>
</tbody>
</table></section>
<section id="get-start-with-dataloader-api">
<h2>Get Start with Dataloader API<a class="headerlink" href="#get-start-with-dataloader-api" title="Permalink to this heading"></a></h2>
<section id="config-dataloader-in-a-yaml-file">
<h3>Config Dataloader in a Yaml File<a class="headerlink" href="#config-dataloader-in-a-yaml-file" title="Permalink to this heading"></a></h3>
<p>Users can use internal dataloader in the following manners. In this case, the dataloader is created after the Quantization object is initialized. As calibration and evaluation may have different transforms and datasets, users can config different dataloaders in a yaml file.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">quantization</span><span class="p">:</span>
<span class="w">  </span><span class="nt">approach</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">post_training_static_quant</span>
<span class="w">  </span><span class="nt">calibration</span><span class="p">:</span>
<span class="w">    </span><span class="nt">dataloader</span><span class="p">:</span>
<span class="w">      </span><span class="nt">dataset</span><span class="p">:</span>
<span class="w">        </span><span class="nt">COCORaw</span><span class="p">:</span>
<span class="w">          </span><span class="nt">root</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/path/to/calibration/dataset</span>
<span class="w">      </span><span class="nt">filter</span><span class="p">:</span>
<span class="w">        </span><span class="nt">LabelBalance</span><span class="p">:</span>
<span class="w">          </span><span class="nt">size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">      </span><span class="nt">transform</span><span class="p">:</span>
<span class="w">        </span><span class="nt">Resize</span><span class="p">:</span>
<span class="w">          </span><span class="nt">size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">300</span>

<span class="nt">evaluation</span><span class="p">:</span>
<span class="w">  </span><span class="nt">accuracy</span><span class="p">:</span>
<span class="w">    </span><span class="nt">metric</span><span class="p">:</span><span class="w"> </span>
<span class="w">      </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">    </span><span class="nt">dataloader</span><span class="p">:</span>
<span class="w">      </span><span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16</span>
<span class="w">      </span><span class="nt">dataset</span><span class="p">:</span>
<span class="w">        </span><span class="nt">COCORaw</span><span class="p">:</span>
<span class="w">          </span><span class="nt">root</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/path/to/evaluation/dataset</span>
<span class="w">      </span><span class="nt">transform</span><span class="p">:</span>
<span class="w">        </span><span class="nt">Resize</span><span class="p">:</span>
<span class="w">          </span><span class="nt">size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">300</span>
<span class="w">  </span><span class="nt">performance</span><span class="p">:</span>
<span class="w">    </span><span class="nt">dataloader</span><span class="p">:</span>
<span class="w">      </span><span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16</span>
<span class="w">      </span><span class="nt">dataset</span><span class="p">:</span>
<span class="w">        </span><span class="nt">dummy_v2</span><span class="p">:</span>
<span class="w">          </span><span class="nt">input_shape</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">224</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">224</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">3</span><span class="p p-Indicator">]</span><span class="w"> </span>
</pre></div>
</div>
</section>
<section id="create-a-user-specific-dataloader">
<h3>Create a User-specific Dataloader<a class="headerlink" href="#create-a-user-specific-dataloader" title="Permalink to this heading"></a></h3>
<p>Users can define their own dataloaders as shown as below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">class</span> <span class="nc">Dataloader</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># operations to add (input_data, label) pairs into self.dataset</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">input_data</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">input_data</span><span class="p">,</span> <span class="n">label</span>

<span class="kn">from</span> <span class="nn">neural_compressor</span> <span class="kn">import</span> <span class="n">quantization</span><span class="p">,</span> <span class="n">PostTrainingQuantConfig</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">PostTrainingQuantConfig</span><span class="p">()</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">Dataloader</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">q_model</span> <span class="o">=</span> <span class="n">quantization</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">calib_dataloader</span><span class="o">=</span><span class="n">dataloader</span><span class="p">,</span>
    <span class="n">eval_func</span><span class="o">=</span><span class="nb">eval</span><span class="p">)</span>
<span class="n">q_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_model</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p>Refer to this <a class="reference external" href="https://github.com/intel/neural-compressor/tree/master/examples/onnxrt/body_analysis/onnx_model_zoo/ultraface/quantization/ptq">example</a> for how to define a customised dataloader.</p></li>
<li><p>Refer to this <a class="reference external" href="https://github.com/intel/neural-compressor/tree/v1.14.2/examples/onnxrt/image_recognition/resnet50/quantization/ptq">example</a> for how to use internal dataloader.</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Intel® Neural Compressor, Intel.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Installation &mdash; Intel® Neural Compressor 2.1 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="User Guide" href="user_guide.html" />
    <link rel="prev" title="Getting Started" href="get_started.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Intel® Neural Compressor
          </a>
            <div class="version">
              <a href="../../../versions.html">2.1▼</a>
              <p>Click link above to switch version</p>
            </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="get_started.html">Getting Started</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#linux-installation">Linux Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="#install-from-binary">Install from Binary</a></li>
<li class="toctree-l3"><a class="reference internal" href="#install-from-source">Install from Source</a></li>
<li class="toctree-l3"><a class="reference internal" href="#install-from-ai-kit">Install from AI Kit</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#windows-installation">Windows Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">Install from Binary</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">Install from Source</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#system-requirements">System Requirements</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#validated-hardware-environment">Validated Hardware Environment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#intel-neural-compressor-supports-cpus-based-on-intel-64-architecture-or-compatible-processors">Intel® Neural Compressor supports CPUs based on Intel 64 architecture or compatible processors:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#intel-neural-compressor-supports-gpus-built-on-intel-s-xe-architecture">Intel® Neural Compressor supports GPUs built on Intel’s Xe architecture:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#intel-neural-compressor-quantized-onnx-models-support-multiple-hardware-vendors-through-onnx-runtime">Intel® Neural Compressor quantized ONNX models support multiple hardware vendors through ONNX Runtime:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#validated-software-environment">Validated Software Environment</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="user_guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="api-doc/apis.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="SECURITY.html">Security Policy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">Repo</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Intel® Neural Compressor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Installation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/docs/source/installation_guide.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="installation">
<h1>Installation<a class="headerlink" href="#installation" title="Permalink to this heading"></a></h1>
<ol>
<li><p><a class="reference external" href="#linux-installation">Linux Installation</a></p>
<p>1.1. <a class="reference external" href="#prerequisites">Prerequisites</a></p>
<p>1.2. <a class="reference external" href="#install-from-binary">Install from Binary</a></p>
<p>1.3. <a class="reference external" href="#install-from-source">Install from Source</a></p>
<p>1.4. <a class="reference external" href="#install-from-ai-kit">Install from AI Kit</a></p>
</li>
<li><p><a class="reference external" href="#windows-installation">Windows Installation</a></p>
<p>2.1. <a class="reference external" href="#prerequisites-1">Prerequisites</a></p>
<p>2.2. <a class="reference external" href="#install-from-binary-1">Install from Binary</a></p>
<p>2.3. <a class="reference external" href="#install-from-source-1">Install from Source</a></p>
</li>
<li><p><a class="reference external" href="#system-requirements">System Requirements</a></p>
<p>3.1. <a class="reference external" href="#validated-hardware-environment">Validated Hardware Environment</a></p>
<p>3.2. <a class="reference external" href="#validated-software-environment">Validated Software Environment</a></p>
</li>
</ol>
<section id="linux-installation">
<h2>Linux Installation<a class="headerlink" href="#linux-installation" title="Permalink to this heading"></a></h2>
<section id="prerequisites">
<h3>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this heading"></a></h3>
<p>You can install Neural Compressor using one of three options: Install single component from binary or source, or get the Intel-optimized framework together with the library by installing the <a class="reference external" href="https://software.intel.com/content/www/us/en/develop/tools/oneapi/ai-analytics-toolkit.html">Intel® oneAPI AI Analytics Toolkit</a>.</p>
<p>The following prerequisites and requirements must be satisfied for a successful installation:</p>
<ul class="simple">
<li><p>Python version: 3.7 or 3.8 or 3.9 or 3.10</p></li>
</ul>
<blockquote>
<div><p>Notes:</p>
<ul class="simple">
<li><p>Please choose one of the basic or full installation mode for your environment, <strong>DO NOT</strong> install both. If you want to re-install with the other mode, please uninstall the current package at first.</p></li>
<li><p>If you get some build issues, please check <a class="reference internal" href="faq.html"><span class="doc">frequently asked questions</span></a> at first.</p></li>
</ul>
</div></blockquote>
</section>
<section id="install-from-binary">
<h3>Install from Binary<a class="headerlink" href="#install-from-binary" title="Permalink to this heading"></a></h3>
<div class="highlight-Shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># install stable basic version from pypi</span>
pip<span class="w"> </span>install<span class="w"> </span>neural-compressor
<span class="c1"># or install stable full version from pypi (including GUI)</span>
pip<span class="w"> </span>install<span class="w"> </span>neural-compressor-full
</pre></div>
</div>
<div class="highlight-Shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># install nightly version</span>
git<span class="w"> </span>clone<span class="w"> </span>https://github.com/intel/neural-compressor.git
<span class="nb">cd</span><span class="w"> </span>neural-compressor
pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
<span class="c1"># install nightly basic version from pypi</span>
pip<span class="w"> </span>install<span class="w"> </span>-i<span class="w"> </span>https://test.pypi.org/simple/<span class="w"> </span>neural-compressor
<span class="c1"># or install nightly full version from pypi (including GUI)</span>
pip<span class="w"> </span>install<span class="w"> </span>-i<span class="w"> </span>https://test.pypi.org/simple/<span class="w"> </span>neural-compressor-full
</pre></div>
</div>
<div class="highlight-Shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># install stable basic version from from conda</span>
conda<span class="w"> </span>install<span class="w"> </span>neural-compressor<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>-c<span class="w"> </span>intel
<span class="c1"># or install stable full version from from conda (including GUI)</span>
conda<span class="w"> </span>install<span class="w"> </span><span class="nv">sqlalchemy</span><span class="o">=</span><span class="m">1</span>.4.27<span class="w"> </span><span class="nv">alembic</span><span class="o">=</span><span class="m">1</span>.7.7<span class="w"> </span>-c<span class="w"> </span>conda-forge
conda<span class="w"> </span>install<span class="w"> </span>neural-compressor-full<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>-c<span class="w"> </span>intel
</pre></div>
</div>
</section>
<section id="install-from-source">
<h3>Install from Source<a class="headerlink" href="#install-from-source" title="Permalink to this heading"></a></h3>
<div class="highlight-Shell notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/intel/neural-compressor.git
<span class="nb">cd</span><span class="w"> </span>neural-compressor
pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
<span class="c1"># build with basic functionality</span>
python<span class="w"> </span>setup.py<span class="w"> </span>install
<span class="c1"># build with full functionality (including GUI)</span>
python<span class="w"> </span>setup.py<span class="w"> </span>--full<span class="w"> </span>install
</pre></div>
</div>
</section>
<section id="install-from-ai-kit">
<h3>Install from AI Kit<a class="headerlink" href="#install-from-ai-kit" title="Permalink to this heading"></a></h3>
<p>The Intel® Neural Compressor library is released as part of the <a class="reference external" href="https://software.intel.com/content/www/us/en/develop/tools/oneapi/ai-analytics-toolkit.html">Intel® oneAPI AI Analytics Toolkit</a> (AI Kit). The AI Kit provides a consolidated package of Intel’s latest deep learning and machine optimizations all in one place for ease of development. Along with Neural Compressor, the AI Kit includes Intel-optimized versions of deep learning frameworks (such as TensorFlow and PyTorch) and high-performing Python libraries to streamline end-to-end data science and AI workflows on Intel architectures.</p>
<p>The AI Kit is distributed through many common channels, including from Intel’s website, YUM, APT, Anaconda, and more. Select and <a class="reference external" href="https://software.intel.com/content/www/us/en/develop/tools/oneapi/ai-analytics-toolkit/download.html">download</a> the AI Kit distribution package that’s best suited for you and follow the <a class="reference external" href="https://software.intel.com/content/www/us/en/develop/documentation/get-started-with-ai-linux/top.html">Get Started Guide</a> for post-installation instructions.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Download</th>
<th>Guide</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://software.intel.com/content/www/us/en/develop/tools/oneapi/ai-analytics-toolkit/">Download AI Kit</a></td>
<td><a href="https://software.intel.com/content/www/us/en/develop/documentation/get-started-with-ai-linux/top.html">AI Kit Get Started Guide</a></td>
</tr>
</tbody>
</table></section>
</section>
<section id="windows-installation">
<h2>Windows Installation<a class="headerlink" href="#windows-installation" title="Permalink to this heading"></a></h2>
<section id="id1">
<h3>Prerequisites<a class="headerlink" href="#id1" title="Permalink to this heading"></a></h3>
<p>The following prerequisites and requirements must be satisfied for a successful installation:</p>
<ul class="simple">
<li><p>Python version: 3.7 or 3.8 or 3.9 or 3.10</p></li>
</ul>
</section>
<section id="id2">
<h3>Install from Binary<a class="headerlink" href="#id2" title="Permalink to this heading"></a></h3>
<div class="highlight-Shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># install stable basic version from pypi</span>
pip<span class="w"> </span>install<span class="w"> </span>neural-compressor
<span class="c1"># or install stable full version from pypi (including GUI)</span>
pip<span class="w"> </span>install<span class="w"> </span>neural-compressor-full
</pre></div>
</div>
<div class="highlight-Shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># install stable basic version from from conda</span>
conda<span class="w"> </span>install<span class="w"> </span>pycocotools<span class="w"> </span>-c<span class="w"> </span>esri
conda<span class="w"> </span>install<span class="w"> </span>neural-compressor<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>-c<span class="w"> </span>intel
<span class="c1"># or install stable full version from from conda (including GUI)</span>
conda<span class="w"> </span>install<span class="w"> </span>pycocotools<span class="w"> </span>-c<span class="w"> </span>esri
conda<span class="w"> </span>install<span class="w"> </span><span class="nv">sqlalchemy</span><span class="o">=</span><span class="m">1</span>.4.27<span class="w"> </span><span class="nv">alembic</span><span class="o">=</span><span class="m">1</span>.7.7<span class="w"> </span>-c<span class="w"> </span>conda-forge
conda<span class="w"> </span>install<span class="w"> </span>neural-compressor-full<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>-c<span class="w"> </span>intel
</pre></div>
</div>
</section>
<section id="id3">
<h3>Install from Source<a class="headerlink" href="#id3" title="Permalink to this heading"></a></h3>
<div class="highlight-Shell notranslate"><div class="highlight"><pre><span></span><span class="w">  </span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/intel/neural-compressor.git
<span class="w">  </span><span class="nb">cd</span><span class="w"> </span>neural-compressor
<span class="w">  </span>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
<span class="w">  </span><span class="c1"># build with basic functionality</span>
<span class="w">  </span>python<span class="w"> </span>setup.py<span class="w"> </span>install
<span class="w">  </span><span class="c1"># build with full functionality (including GUI)</span>
<span class="w">  </span>python<span class="w"> </span>setup.py<span class="w"> </span>--full<span class="w"> </span>install
</pre></div>
</div>
</section>
</section>
<section id="system-requirements">
<h2>System Requirements<a class="headerlink" href="#system-requirements" title="Permalink to this heading"></a></h2>
<section id="validated-hardware-environment">
<h3>Validated Hardware Environment<a class="headerlink" href="#validated-hardware-environment" title="Permalink to this heading"></a></h3>
<section id="intel-neural-compressor-supports-cpus-based-on-intel-64-architecture-or-compatible-processors">
<h4>Intel® Neural Compressor supports CPUs based on <a class="reference external" href="https://en.wikipedia.org/wiki/X86-64">Intel 64 architecture or compatible processors</a>:<a class="headerlink" href="#intel-neural-compressor-supports-cpus-based-on-intel-64-architecture-or-compatible-processors" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Intel Xeon Scalable processor (formerly Skylake, Cascade Lake, Cooper Lake, Ice Lake, and Sapphire Rapids)</p></li>
<li><p>Intel Xeon CPU Max Series (formerly Sapphire Rapids HBM)</p></li>
</ul>
</section>
<section id="intel-neural-compressor-supports-gpus-built-on-intel-s-xe-architecture">
<h4>Intel® Neural Compressor supports GPUs built on Intel’s Xe architecture:<a class="headerlink" href="#intel-neural-compressor-supports-gpus-built-on-intel-s-xe-architecture" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Intel Data Center GPU Flex Series (formerly Arctic Sound-M)</p></li>
<li><p>Intel Data Center GPU Max Series (formerly Ponte Vecchio)</p></li>
</ul>
</section>
<section id="intel-neural-compressor-quantized-onnx-models-support-multiple-hardware-vendors-through-onnx-runtime">
<h4>Intel® Neural Compressor quantized ONNX models support multiple hardware vendors through ONNX Runtime:<a class="headerlink" href="#intel-neural-compressor-quantized-onnx-models-support-multiple-hardware-vendors-through-onnx-runtime" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Intel CPU, AMD/ARM CPU, and NVidia GPU. Please refer to the validated model <a class="reference external" href="./validated_model_list.html#validated-onnx-qdq-int8-models-on-multiple-hardware-through-onnx-runtime">list</a>.</p></li>
</ul>
</section>
</section>
<section id="validated-software-environment">
<h3>Validated Software Environment<a class="headerlink" href="#validated-software-environment" title="Permalink to this heading"></a></h3>
<ul class="simple">
<li><p>OS version: CentOS 8.4, Ubuntu 22.04</p></li>
<li><p>Python version: 3.7, 3.8, 3.9, 3.10</p></li>
</ul>
<table class="docutils">
<thead>
  <tr style="vertical-align: middle; text-align: center;">
    <th>Framework</th>
    <th>TensorFlow</th>
    <th>Intel<br>TensorFlow</th>
    <th>Intel®<br>Extension for<br>TensorFlow*</th>
    <th>PyTorch</th>
    <th>Intel®<br>Extension for<br>PyTorch*</th>
    <th>ONNX<br>Runtime</th>
    <th>MXNet</th>
  </tr>
</thead>
<tbody>
  <tr align="center">
    <th>Version</th>
    <td class="tg-7zrl"><a href=https://github.com/tensorflow/tensorflow/tree/v2.12.0>2.12.0</a><br>
    <a href=https://github.com/tensorflow/tensorflow/tree/v2.11.0>2.11.0</a><br>
    <a href=https://github.com/tensorflow/tensorflow/tree/v2.10.1>2.10.1</a><br></td>
    <td class="tg-7zrl"><a href=https://github.com/Intel-tensorflow/tensorflow/tree/v2.11.0>2.11.0</a><br>
    <a href=https://github.com/Intel-tensorflow/tensorflow/tree/v2.10.0>2.10.0</a><br>
    <a href=https://github.com/Intel-tensorflow/tensorflow/tree/v2.9.1>2.9.1</a><br></td>
    <td class="tg-7zrl"><a href=https://github.com/intel/intel-extension-for-tensorflow/tree/v1.1.0>1.1.0</a><br>
    <a href=https://github.com/intel/intel-extension-for-tensorflow/tree/v1.0.0>1.0.0</a></td>
    <td class="tg-7zrl"><a href=https://download.pytorch.org/whl/torch_stable.html>2.0.0+cpu</a><br>
    <a href=https://download.pytorch.org/whl/torch_stable.html>1.13.0+cpu</a><br>
    <a href=https://download.pytorch.org/whl/torch_stable.html>1.12.1+cpu</a><br></td>
    <td class="tg-7zrl"><a href=https://github.com/intel/intel-extension-for-pytorch/tree/v2.0.0+cpu>2.0.0+cpu</a><br>
    <a href=https://github.com/intel/intel-extension-for-pytorch/tree/v1.13.0+cpu>1.13.0+cpu</a><br>
    <a href=https://github.com/intel/intel-extension-for-pytorch/tree/v1.12.100>1.12.1+cpu</a><br></td>
    <td class="tg-7zrl"><a href=https://github.com/microsoft/onnxruntime/tree/v1.14.1>1.14.1</a><br>
    <a href=https://github.com/microsoft/onnxruntime/tree/v1.13.1>1.13.1</a><br>
    <a href=https://github.com/microsoft/onnxruntime/tree/v1.12.1>1.12.1</a><br></td>
    <td class="tg-7zrl"><a href=https://github.com/apache/incubator-mxnet/tree/1.9.1>1.9.1</a><br></td>
  </tr>
</tbody>
</table><blockquote>
<div><p><strong>Note:</strong>
Set the environment variable <code class="docutils literal notranslate"><span class="pre">TF_ENABLE_ONEDNN_OPTS=1</span></code> to enable oneDNN optimizations if you are using TensorFlow before v2.9. oneDNN is the default for TensorFlow since <a class="reference external" href="https://github.com/tensorflow/tensorflow/releases/tag/v2.9.0">v2.9</a> (<a class="reference external" href="https://www.intel.com/content/www/us/en/products/platforms/details/cascade-lake.html">Intel Cascade Lake</a> and newer CPUs).</p>
</div></blockquote>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="get_started.html" class="btn btn-neutral float-left" title="Getting Started" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="user_guide.html" class="btn btn-neutral float-right" title="User Guide" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Intel® Neural Compressor, Intel.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
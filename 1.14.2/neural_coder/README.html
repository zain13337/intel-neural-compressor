<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Neural Coder &mdash; Intel® Neural Compressor  documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Intel® Neural Compressor
          </a>
            <div class="version">
              <a href="../../versions.html">1.14.2▼</a>
              <p>Click link above to switch version</p>
            </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../README.html">Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api-documentation/apis.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/doclist.html">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/contributions.html">Contribution Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">Intel® Neural Compressor repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Intel® Neural Compressor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Neural Coder</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/neural_coder/README.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="neural-coder">
<h1>Neural Coder<a class="headerlink" href="#neural-coder" title="Permalink to this headline">¶</a></h1>
<div class="section" id="what-do-we-offer">
<h2>What do we offer?<a class="headerlink" href="#what-do-we-offer" title="Permalink to this headline">¶</a></h2>
<p>Neural Coder is a novel component under Intel® Neural Compressor to further simplify the deployment of deep learning models via one-click automated code changes for device switch (e.g., CUDA to CPU) and optimization enabling. Subsequently, Neural Coder can also perform automated benchmark on all applicable optimization sets acquired from the automated enabling, and evaluate for the best out-of-box performance.</p>
<p>Neural Coder leverages static program analysis techniques and heuristic optimization rules to simplify the usage of various Deep Learning optimization APIs for increasing computation efficiency of AI models and improving user experience for general AI customers. We demonstrate great improvement of developer productivity and aim to facilitate enhanced Deep Learning acceleration adoption via this toolkit.</p>
<p>Neural Coder helps you code Deep Learning optimizations automatically into your scripts. For example, to apply</p>
<ul class="simple">
<li><p>Automatic Mixed Precision (torch.cpu.amp.autocast)</p></li>
<li><p>JIT Script computation graph transformation (torch.jit.script)</p></li>
<li><p>Channels Last memory format transformation (torch.channels_last)</p></li>
</ul>
<p>simultaneously on below PyTorch evaluation code, we generate the optimized code in one-click by detecting the correct position to insert the correct API code lines:</p>
<div class="highlight-diff notranslate"><div class="highlight"><pre><span></span>  import torch
  import torchvision.models as models
  my_model = models.resnet50(pretrained=True)
<span class="gi">+ import torch</span>
<span class="gi">+ with torch.no_grad():</span>
<span class="gi">+     my_model = my_model.to(memory_format=torch.channels_last)</span>
<span class="gi">+ import torch</span>
<span class="gi">+ with torch.no_grad():</span>
<span class="gi">+     my_model.eval()</span>
<span class="gi">+     my_model = torch.jit.script(my_model)</span>
<span class="gi">+     my_model = torch.jit.freeze(my_model)</span>
  my_model.eval()
  batch_size = 112
  input = torch.rand(batch_size, 3, 224, 224)
  with torch.no_grad():
<span class="gi">+     import torch</span>
<span class="gi">+     with torch.cpu.amp.autocast(enabled=True, dtype=torch.bfloat16):</span>
          my_model(input)
</pre></div>
</div>
</div>
<div class="section" id="getting-started">
<h2>Getting Started!<a class="headerlink" href="#getting-started" title="Permalink to this headline">¶</a></h2>
<p>There are currently 2 ways to use Neural Coder for automatic quantization enabling and benchmark.</p>
<div class="section" id="jupyter-lab-extension">
<h3>Jupyter Lab Extension<a class="headerlink" href="#jupyter-lab-extension" title="Permalink to this headline">¶</a></h3>
<p>We offer Neural Coder as an extension plugin in Jupyter Lab. This enables users to utilize Neural Coder while writing their Deep Learning models in Jupyter Lab coding platform. Users can simply search for <code class="docutils literal notranslate"><span class="pre">jupyter-lab-neural-compressor</span></code> in the Extension Manager in JupyterLab and install Neural Coder with one click. For more details, please refer to this <a class="reference internal" href="extensions/neural_compressor_ext_lab/README.html"><span class="doc">guide</span></a></p>
</div>
<div class="section" id="python-api">
<h3>Python API<a class="headerlink" href="#python-api" title="Permalink to this headline">¶</a></h3>
<p>There are 3 user-facing APIs for Neural Coder: enable, bench and superbench. For more details, please refer to this <a class="reference internal" href="docs/PythonAPI.html"><span class="doc">guide</span></a>. We have provided a <a class="reference internal" href="docs/SupportMatrix.html"><span class="doc">list</span></a> of supported Deep Learning optimization features. Specifically for quantization, we provide an auto-quantization API that helps automatically enable quantization on Deep Learning models and automatically evaluates for the best performance on the model with no manual coding needed. Supported features include Post-Training Static Quantization, Post-Training Dynamic Quantization, and Mixed Precision. For more details, please refer to this <a class="reference internal" href="docs/Quantization.html"><span class="doc">guide</span></a>.</p>
</div>
</div>
<div class="section" id="contact">
<h2>Contact<a class="headerlink" href="#contact" title="Permalink to this headline">¶</a></h2>
<p>Please contact us at <a class="reference external" href="mailto:inc&#46;maintainers&#37;&#52;&#48;intel&#46;com">inc<span>&#46;</span>maintainers<span>&#64;</span>intel<span>&#46;</span>com</a> for any Neural Coder related question.</p>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Intel® Neural Compressor.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
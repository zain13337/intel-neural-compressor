<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Full Publications (42) &mdash; Intel® Neural Compressor  documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Intel® Neural Compressor
          </a>
            <div class="version">
              <a href="../../versions.html">1.14.2▼</a>
              <p>Click link above to switch version</p>
            </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../README.html">Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api-documentation/apis.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="doclist.html">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributions.html">Contribution Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">Intel® Neural Compressor repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Intel® Neural Compressor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Full Publications (42)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/docs/publication_list.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="full-publications-42">
<h1>Full Publications (42)<a class="headerlink" href="#full-publications-42" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id1">
<h2>2022 (24)<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://www.intel.com/content/www/us/en/developer/articles/technical/innovation-of-ai-software-extension-tensorflow.html">Meet the Innovation of Intel AI Software: Intel® Extension for TensorFlow*</a> (Oct 2022)</p></li>
<li><p><a class="reference external" href="https://www.intel.com/content/www/us/en/developer/articles/technical/pytorch-inference-with-intel-neural-compressor.html#gs.gnq0cj">PyTorch* Inference Acceleration with Intel® Neural Compressor</a> (Oct 2022)</p></li>
<li><p>Neural Coder, a new plug-in for Intel Neural Compressor was covered by <a class="reference external" href="https://intel.sharepoint.com/sites/iLit-MyLearning/Shared%20Documents/My%20Learning/Haihao/MSR/2022/o%09https:/twitter.com/IntelDevTools/status/1583629213697212416?s=20&amp;t=f2dXY_g9-bCO-GQm-S6Btg">Twitter</a>, <a class="reference external" href="https://www.linkedin.com/posts/intel-software_oneapi-ai-deeplearning-activity-6989377309917007872-Dbzg?utm_source=share&amp;utm_medium=member_desktop">LinkedIn</a>, and <a class="reference external" href="https://mp.weixin.qq.com/s/LL-4eD-R0YagFgODM23oQA">Intel Developer Zone</a> from Intel, and <a class="reference external" href="https://twitter.com/IntelDevTools/status/1583629213697212416/retweets">Twitter</a> and <a class="reference external" href="https://www.linkedin.com/feed/update/urn:li:share:6990377841435574272/">LinkedIn</a> from Hugging Face. (Oct 2022)</p></li>
<li><p>Intel Neural Compressor successfully landed on <a class="reference external" href="https://console.cloud.google.com/marketplace/product/bitnami-launchpad/inc-tensorflow-intel?project=verdant-sensor-286207">GCP</a>, <a class="reference external" href="https://aws.amazon.com/marketplace/pp/prodview-yjyh2xmggbmga#pdp-support">AWS</a>, and <a class="reference external" href="https://azuremarketplace.microsoft.com/en-us/marketplace/apps/bitnami.inc-tensorflow-intel">Azure</a> marketplace. (Oct 2022)</p></li>
<li><p><a class="reference external" href="https://twitter.com/i/status/1574909338203967497">Neural Coder (Intel Neural Compressor Plug-in): One-Click, No-Code Solution (Pat’s Keynote IntelON 2022)</a> (Sep 2022)</p></li>
<li><p><a class="reference external" href="https://medium.com/intel-analytics-software/alibaba-cloud-collaborates-with-intel-neural-compressor-for-better-productivity-and-performance-83cdb6500420">Alibaba Cloud and Intel Neural Compressor Deliver Better Productivity for PyTorch Users</a> [<a class="reference external" href="https://mp.weixin.qq.com/s/LL-4eD-R0YagFgODM23oQA">Chinese version</a>] (Sep 2022)</p></li>
<li><p><a class="reference external" href="https://medium.com/intel-analytics-software/efficient-text-classification-with-intel-neural-compressor-4853296deeac">Efficient Text Classification with Intel Neural Compressor</a> (Sep 2022)</p></li>
<li><p><a class="reference external" href="https://medium.com/intel-analytics-software/dynamic-neural-architecture-search-with-intel-neural-compressor-7b05eaf325f3">Dynamic Neural Architecture Search with Intel Neural Compressor</a> (Sep 2022)</p></li>
<li><p><a class="reference external" href="https://medium.com/intel-analytics-software/easy-quantization-in-pytorch-using-fine-grained-fx-80be2c4bc2d6">Easy Quantization in PyTorch Using Fine-Grained FX</a> (Sep 2022)</p></li>
<li><p><a class="reference external" href="https://medium.com/intel-analytics-software/one-click-enable-intel-neural-compressor-features-in-pytorch-scripts-5d4e31f5a22b">One-Click Enabling of Intel Neural Compressor Features in PyTorch Scripts</a> (Aug 2022)</p></li>
<li><p><a class="reference external" href="https://zhuanlan.zhihu.com/p/552484413?utm_source=ZHShareTargetIDMore&amp;utm_medium=social&amp;utm_oi=667097517833981952">Deep learning inference optimization for Address Purification</a> (Aug 2022)</p></li>
<li><p><a class="reference external" href="https://www.intel.com/content/www/us/en/developer/videos/accelerate-inference-without-sacrificing-accuracy.html#gs.9yottx">Accelerate AI Inference without Sacrificing Accuracy</a> (Jun 2022)</p></li>
<li><p><a class="reference external" href="https://medium.com/pytorch/pytorch-inference-acceleration-with-intel-neural-compressor-842ef4210d7d">PyTorch Inference Acceleration with Intel® Neural Compressor</a> (Jun 2022)</p></li>
<li><p><a class="reference external" href="https://huggingface.co/blog/intel">Intel and Hugging Face Partner to Democratize Machine Learning Hardware Acceleration</a> (Jun 2022)</p></li>
<li><p><a class="reference external" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/neural-compressor.html">Intel® Neural Compressor oneAPI</a> (Jun 2022)</p></li>
<li><p><a class="reference external" href="https://networkbuilders.intel.com/solutionslibrary/intel-deep-learning-boost-boost-network-security-ai-inference-performance-in-google-cloud-platform-gcp-technology-guide">Intel® Deep Learning Boost - Boost Network Security AI Inference Performance in Google Cloud Platform (GCP)</a> (Apr 2022)</p></li>
<li><p><a class="reference external" href="https://pytorch.org/ecosystem/">INC as PT ecosystem project</a> (Apr 2022)</p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=-_2ha2CNWXA">Dynamic Quantization with Intel Neural Compressor and Transformers</a> (Mar 2022)</p></li>
<li><p><a class="reference external" href="https://builders.intel.com/docs/networkbuilders/ai-technologies-unleash-ai-innovation-in-network-applications-solution-brief-1637303210.pdf">New instructions in the Intel® Xeon® Scalable processors combined with optimized software frameworks enable real-time AI within network workloads</a> (Feb 2022)</p></li>
<li><p><a class="reference external" href="https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Quantizing-ONNX-Models-using-Intel-Neural-Compressor/post/1355237">Quantizing ONNX Models using Intel® Neural Compressor</a> (Feb 2022)</p></li>
<li><p><a class="reference external" href="https://www.intel.com/content/www/us/en/developer/articles/technical/quantize-ai-by-oneapi-analytics-on-alibaba-cloud.html">Quantize AI Model by Intel® oneAPI AI Analytics Toolkit on Alibaba Cloud</a> (Feb 2022)</p></li>
<li><p><a class="reference external" href="https://sigopt.com/blog/intel-neural-compressor-quantization-with-sigopt/">Intel Neural Compressor Quantization with SigOpt</a> (Jan 2022)</p></li>
<li><p><a class="reference external" href="https://twitter.com/IntelAI/status/1469079414562557952">AI Performance and Productivity with Intel® Neural Compressor</a> (Jan 2022)</p></li>
<li><p><a class="reference external" href="https://pytorch.org/tutorials/recipes/intel_neural_compressor_for_pytorch.html">Ease-of-use quantization for PyTorch with Intel® Neural Compressor</a> (Jan 2022)</p></li>
</ul>
</div>
<div class="section" id="id2">
<h2>2021 (14)<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://space.bilibili.com/1840724569?from=search&amp;seid=8673550305007703901&amp;spm_id_from=333.337.0.0">Intel Neural Compressor Tutorial on BiliBili</a> (Dec 2021)</p></li>
<li><p><a class="reference external" href="https://gestaltit.com/tech-talks/intel/intel-2021/jpwarren/faster-ai-ml-results-with-intel-neural-compressor">Faster AI/ML Results With Intel Neural Compressor</a> (Dec 2021)</p></li>
<li><p><a class="reference external" href="https://nips.cc/Conferences/2021/Schedule?showEvent=21839">Prune Once for All: Sparse Pre-Trained Language Models</a> (Nov 2021)</p></li>
<li><p><a class="reference external" href="https://www.intel.com/content/www/us/en/artificial-intelligence/posts/optimization-with-intel-neural-compressor.html">Faster, Easier Optimization with Intel® Neural Compressor</a> (Nov 2021)</p></li>
<li><p><a class="reference external" href="https://www.intel.com/content/www/us/en/developer/videos/accelerate-deep-learning-with-intel-tensorflow.html#gs.9yrw90">Accelerate Deep Learning with Intel® Extension for TensorFlow*</a> (Oct 2021)</p></li>
<li><p><a class="reference external" href="https://events.linuxfoundation.org/lf-ai-data-day-onnx-community-virtual-meetup-fall/program/schedule">Intel® Neural Compressor: A Scalable Quantization Tool for ONNX Models</a> (Oct 2021)</p></li>
<li><p><a class="reference external" href="https://www.intel.com/content/www/us/en/artificial-intelligence/posts/intel-mlperf-inference-performance.html">A “Double Play” for MLPerf™ Inference Performance Gains with 3rd Generation Intel® Xeon® Scalable Processors</a> (Sep 2021)</p></li>
<li><p><a class="reference external" href="https://software.intel.com/content/www/us/en/develop/articles/optimize-tensorflow-pre-trained-model-inference.html">Optimize TensorFlow Pre-trained Model for Inference</a> (Jun 2021)</p></li>
<li><p><a class="reference external" href="https://www.intel.com/content/www/us/en/artificial-intelligence/posts/tencent-3d-digital-face-reconstruction.html">3D Digital Face Reconstruction Solution enabled by 3rd Gen Intel® Xeon® Scalable Processors</a> (Apr 2021)</p></li>
<li><p><a class="reference external" href="https://www.intel.com/content/www/us/en/artificial-intelligence/posts/alibaba-lpot.html">Accelerating Alibaba Transformer model performance with 3rd Gen Intel® Xeon® Scalable Processors (Ice Lake) and Intel® Deep Learning Boost</a> (Apr 2021)</p></li>
<li><p><a class="reference external" href="https://www.intel.com/content/www/us/en/artificial-intelligence/posts/3rd-gen-xeon-mlperf-performance-gains.html">MLPerf™ Performance Gains Abound with latest 3rd Generation Intel® Xeon® Scalable Processors</a> (Apr 2021)</p></li>
<li><p><a class="reference external" href="https://techdecoded.intel.io/essentials/using-low-precision-optimizations-for-high-performance-dl-inference-applications/#gs.z20k91">Using Low-Precision Optimizations for High-Performance DL Inference Applications</a> (Apr 2021)</p></li>
<li><p><a class="reference external" href="https://wiki.lfaidata.foundation/pages/viewpage.action?pageId=35160391">Quantization support for ONNX using LPOT (Low precision optimization tool)</a> (Mar 2021)</p></li>
<li><p><a class="reference external" href="https://www.nextplatform.com/2021/02/01/cern-uses-dlboost-oneapi-to-juice-inference-without-accuracy-loss/">DL Boost Quantization with CERN’s 3D-GANs model</a> (Feb 2021)</p></li>
</ul>
</div>
<div class="section" id="id3">
<h2>2018 - 2020 (4)<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://indico.cern.ch/event/852553/contributions/4059283/attachments/2126838/3581708/Rehm_Florian-IML-Reduced_Precision.pdf">Reduced Precision Strategies for Deep Learning: 3DGAN Use Case</a> - <a class="reference external" href="https://indico.cern.ch/event/852553/contributions/4059283/attachments/2126838/3588271/IML2020_wedam_rehm.mp4">presentation</a> on <a class="reference external" href="https://indico.cern.ch/event/852553/contributions/4059283/">4th IML Machine Learning Workshop</a> (Oct 2020)</p></li>
<li><p><a class="reference external" href="https://www.intel.com/content/www/us/en/artificial-intelligence/posts/intel-low-precision-optimization-tool.html">Intel Neural Compressor</a> (Sep 2020)</p></li>
<li><p><a class="reference external" href="https://www.intel.com/content/www/us/en/developer/articles/technical/lower-numerical-precision-deep-learning-inference-and-training.html">Lower Numerical Precision Deep Learning Inference and Training</a> (May 2018)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1805.08691">Highly Efficient 8-bit Low Precision Inference of Convolutional Neural Networks with IntelCaffe</a> (May 2018)</p></li>
</ul>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Intel® Neural Compressor.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>